[["index.html", "The R4GC Book Learn Data Science with R: Notes and tutorials from the R4GC Community ‘Lunch and Learn’ meetups Raison d’être R4GC Community Book source code Disclaimer Contributors Licenses Key principles How to contribute About authors", " The R4GC Book Learn Data Science with R: Notes and tutorials from the R4GC Community ‘Lunch and Learn’ meetups Dmitry Gorodnichy and Patrick Little https://open-canada.github.io/r4gc (License: CC BY 4.0) December 2021 Raison d’être This book is prepared as part of the R4GC Community skill enhancing and knowledge gathering exercise. It aims at consolidating the knowledge-based that is being gathered by the R4GC Community spread across various R4GC community portals and discussions. It also serves to illustrate - as always with source code - one of the most powerful features of R, which is the collaborative peer-reviewed development of data science codes and reports using R Markdown. R4GC Community R4GC Community (formerly called “Use R!” GCCollab community) was created in March 2021 to bring together the R users across the Government of Canada. Here we gather and curate the knowledgebase related to the use of R within the Government of Canada. Everyone is welcome to join, whether you are an advanced R user, just starting learning it, or simply want to learn more about data science and how it is done. The idea to create this group came during the GC Data2021 Conference workshop on Data Engineering Challenges and Solutions: Demonstration of Shiny [^gcdata2021]. The highest voted question during the discussion there was : “How can I get more help for our members to enhance their knowledge and”spread the word” and raise more awareness regard to this tool?“ The creation of this community group is the answer to this question. By November 2021, the R4GC GCCollab group has been become one of the largest active data science practitioners groups in Canada, counting over a quarter thousand of members. The weekly “Lunch and Learn Data Science with R” meetups organized by the R4GC Community have been attended by data practitioners from over twenty government departments, and generated hundreds of questions/answers, a dozen of tutorials, multiple open to use applications, and thousands of line of open code. “Lunch and Learn Data Science with R” meetups “Building advanced Data Science skills using R, together - one meeting at a time!” These informal meetings are organized weekly during Friday lunch time (from 12:05 to 12:55). There data scientists wanting to upscale their knowledge of R and other Data Science related subjects get together to show and discuss their R codes and share their data coding tricks and methodologies. Normally, each session is focused on a particular subject or project with the codes shared on GCcode. No registration is required to join the meeting. However, in order to view the notes and video-recordings from these meetups, you need to join this sub-group: https://gccollab.ca/groups/about/7855030. For Agenda and Dial-in MS Teams numbers please see Group Events page at https://gccollab.ca/event_calendar/group/7391537. Community portals The R4GC community makes used of the following collaborative platforms provided by Shared Services Canada. GCcode group - r4gc URL: https://gccode.ssc-spc.gc.ca/r4gc GCcode is the GitLab solution that is accessible from within the GC network. As such, it allows one to view and update (pull and push) codes and documentation with a single click of button on a GC laptop from an RStudio. The tutorial on how to do it is developed. The ‘r4gc’ group has been created within GCcodes, where the codes, tutorials and other resources are gathered. It contains three main folders: /codes. - This is where “raw” (not-reviewed, unedited) R codes contributed by GC community are uploaded. Currently, this includes codes for analyzing and visualizing PSES (Public Service Employee Survey) results, ATIP requests, COVID-19 statistics, and various codes for ease of day to day work and maintenance. Some codes are readily available to become packages, some are short code snippets taken from various blogs, question and answer portals, such as www.stackoverflow.org and www.rseek.org, and open-source textbooks. /gc-packages. - This is where the work on packages being developed from the submitted “raw” codes is happening. Currently it includes repositories for building packages to process PSES results, COVID-19 data, and the utility functions package for data engineering and efficient data processing. /resources. - This where the rest of knowledge-base is gathered, including the tutorials, slides, and codes presented at the community weekly ‘Lunch and Learn’ meetups. GCcollab: R4GC (Use R) URL: https://gccollab.ca/groups/profile/7391537/enuse-rfruse-r GCcollab allows one to participate in the discussion from within and outside GC network (for registered users). This makes it convenient for gathering information from any sources, including those that my not be available from within the GC network. In order to facilitate the curation of knowledge, a number of discussion threads have been created there to address of topics of highest interest for the R4GC community. These are reviewed and updated regularly, commonly as part of community weekly meetups. GCwiki: UseR! URL: https://wiki.gccollab.ca/UseR! This platform is used to consolidate all discussion topics in one place and link them with other data science resources in the wiki space. GitHub: open-canada URL: https://open-canada.github.io/UseR/ Inline with the GC policies of open science and open data , since most information gathered by the R4GC community is unclassified and comes from public domain, a public facing organizational account has been created on GitHub (https://github.com/open-canada) for sharing and growing the R4GC community knowledgebase. This is where public-facing community outputs are gathered, including the growing collection of Web Apps and codes that were built with contributions from GC data scientists using open source tools and data, located at https://github.com/open-canada/Apps Community presentations International Methodology Symposium (October 2021) The work of the R4GC community was presented at the 2021 International Methodology Symposium organized by Statistics Canada in October 2021. The slides for this presentation are available here: in English and en français. GC Data Conference (February, 2021) The earlier work of community members was also presented at the 2021 GC Data Conference Data Literacy Fest Workshop “Data Engineering Challenges and Solutions: Demo of Shiny” in February 2021. The video-recording of this workshop was made available by conference organizers and is available on YouTube. Book source code This is book is built using the bookdown R package in RStudio. It is hosted at Open Canada GitHub repo https://open-canada.github.io/r4gc. The source code of it located at https://github.com/open-canada/r4gc. Thus built, the book enables easy collaboration, transparency and peer-reviewing. Disclaimer The views and opinions expressed in this article are those of the authors and do not necessarily reflect the official policy or position of any agency of the Government of Canada. Contributors R4GC is a collaborative effort of many people who have contributed to the development of the knowledgebase that is gathered in this book. They are listed below. Jonathan Dench, Joseph Stinziano, Henry Luan, Eric Littlewood, Philippe-Israel Morin, Tony Machado, Maxime Girouard, Martin Jean, Tim Roy, Mehrez Samaali, Sylvain Paquet, Dejan Pavlic, Utku Suleymanoglu, Additionally, much support has been also received from wider international R community through stackoverflow.org portal and knowledge-sharing events organized by the RStudio, as well as from several other Government of Canada employees who remained anonymous. Their help is greatly appreciated. Licenses This book is licensed under the Creative Commons Attribution 4.0 License, and is (and will always be) free to use. Key principles Open data, open source, open science This book contains only the information and knowledge that was obtained from public domain, using the Open Government principles Chatham House Rule This book is prepared using the Chatham House rule. The Chatham House Rule helps create a trusted environment to understand and resolve complex problems through dialog and timely open communication. Its guiding spirit is: share the information you receive, but do not reveal the identity of who said it. Hence, no attributions are made and the identity of speakers and participants is not disclosed. It is based on the views and codes contributed by community members as part of ongoing community events interactions. Offered as a means to facilitate the discussion, the document does not constitute an analytical document, nor does it represent any formal position of any organization involved. How to contribute Any chapter of this book can be edited by simply clicking on the “edit” button, which will lead to the corresponding source Rmd file in the book’s repo, where you can make a change in the document (in doing so, this repo will forked at your github account ) and submit ir to the book editor (by submitting the merge request). Alternatively, you can always contact the R4GC group lead at the contact listed below and attend R4GC weekly meetups. About authors Dmitry Gorodnichy is Research Data Scientist with the Chief Data Office at the Canadian Border Services Agency. Patrick Little is Adviser on the Open Government systems team at the Treasury Board of Canada Secretariat. Contacts For questions and feedback, please contact Dmitry Gorodnichy: dmitry.gorodnichy@cbsa-asfc.gc.ca "],["français.html", "Français", " Français Pour l’instant, ce livre est développé seulement en anglais. Cependant, plusieurs de commentaires et trucs qu’on partage dans notre communauté proviens également dans la langue française aussi. On espère qu’un moment donné on peut d’avoir ce livre dans le deux langues officielles: en anglais et en français. On même peux se servir des outils automatisés et intelligence artificielle - car nous sommes les scientifiques de données, n’est pas ? - pour automatiser le traduction de contexte de ce livre! Si vous êtes intéressé de contribuer à nos efforts de traduire ce livre dans le langue de votre choix, veuillez contacter modérateur de groupe. "],["preface.html", "Preface Introduction Data as ‘electricity’ of the 21st century Data Engineering challenge Towards open source and open science Pedagogical approach Book outline", " Preface Introduction Many Government of Canada groups are developing codes to process and visualize various kinds data, often duplicating each other’s efforts, with sub-optimal efficiency and limited level of code quality reviewing. This book presents a pan-government initiative to address this problem. The idea is to collaboratively build a common repository of code and knowledgebase for use by anyone in the government to perform many common data science tasks, and, in doing that, help each other to master both the data science coding skills and the industry standard collaborative practices. The book explains why R language is used as the language of choice for collaborative data science code development. It summaries R advantages and addresses its limitations, establishes the taxonomy of discussion topics of highest interested to the GC data scientists working with R, provides an overview of used collaborative platforms, and presents the results obtained to date. Even though the code knowledgebase is developed mainly in R, it is meant to be valuable also for data scientists coding in Python and other development environments. Data as ‘electricity’ of the 21st century Data is the ‘electricity’ of the 21st century. It is everywhere. Everybody is using it, and one may not need special training or certification to work with data. However, in contrast to working with electricity, working with data relies on the use of data processing tools (codes), the number and complexity of which increases daily, and which are developed by other data practitioners. In other words, data science - by its nature - is the science that is fueled by collaboration of data scientists and that heavily relies on the quality of the shared data processing codes. Globally, and in the Government of Canada (GC) in particular, data practitioners come from many different backgrounds and may not have equal level of code programming training, which hinders the development of high-quality (efficient, scalable and re-usable) codes for data science problems. This gap and the need for collaboration for data scientists, specifically those coding in R language, has been raised at the 2021 GC Data Conference Workshop on Data Engineering in February 2021. This book addresses this need. Data Engineering challenge This effort has started from addressing the problem of data engineering, where it is understood - in analogy with the definition of software engineering by IEEE [2] - as the field of science and technology that deals with “developing scientific and technological knowledge, methods, and experience to the design, implementation, testing, and documentation” of data-driven systems and solutions; or - in analogy with the definition of software engineering at Google [3] - as the field that “encompasses not just the act of writing code [for data analysis, in our case], but all of the tools and processes an organization uses to build and maintain that code over time”. Towards open source and open science The spectacular growth of data science tools development is overwhelmingly attributed to the collaborative open nature of the current data science code development practices. Consequently, Canadian government is also adopting open source industry standards for data coding and reporting. Major shift towards enabling and promoting such practices within the government has started recently, when Government of Canada adopted a number of policies in support of Digital, Open Science, and Open Government [4], when Shared Services of Canada deployed a number of collaboration platforms that are now available to all GC organizations, and when IT Security of most GC departments approved the use of open-source data science tools such as R and R Studio. Pedagogical approach The approach to teaching (mastering) R in this book is very different from that of what most (all?) other open-source R tutorials one will find on the Web. It is driven by the personal professional backgrounds and experiences of the authors (one comes from Computing Science, the other from Open Government) working with R and open data. - The consistent deliberate effort throughout this book, as throughout all meetups and discussion of the authors in the R4GC community portal, is put into going away from judging the quality of your R skills by how good your outputs (graphs, reports etc) are , but how good the code that generated your outputs is. Is it easy to understand (without having you to read comments or documentation)? Is it easy to debug Is it modular? Is it as simple as possible? Is it re-usable? Is it scalable (to larger, or different data)? Does it have least possible number of dependencies (packages), and those that he uses are the best (most effciient and robust, and best supported) for the purpose? We focus on ensuring that from the very first lines of code, you code is written properly, i.e, it conforms to all above criteria. In order to achieve that, in contrast to all other tutorials (such as those provided by fabulous RStudio team), the first package we always introduce is ‘data.table’, and not anything else. All other packages and codes will be added later and through the use of ‘data.table’ by default. Why? - Read the section on R limitations @ref{r_limitations}. Importantly, you will soon see that you code will not only runs much faster - so you can run it even no your regular 16 Gb RAM laptop, it also takes less screen space and is easier to read! And … you will never compare your code to Italian pasta dish (“spaghetti”), and it will get used and possibly further extended by others, and bring more joy to your life. Book outline The book is organized in several parts, according to the topics of interest discussed in the GCcollab R4GC group. Discussions around these topics are reviewed and updated regularly, commonly as part of weekly community meetups. Part I is dedicated to General discussions, which includes the following: Why R? Learn R: Right way! Great open-source textbooks Events and forums for R users Using R with GC data infrastructure Open source policies and guidelines Part II is dedicated to the Best Practices and Efficient Coding in R and includes the following: Use R efficiently with data.table! R and Python, Unite! From Excel to R Reading various kinds of data in R Other tips and rules for coding well in R Part III is dedicated to Visualization and Reporting and includes the following: Literate programming and automated reports with ‘rmarkdown’ Data visualization with ‘ggplot2’ and its extensions Interactive interfaces, applications and dashboards with ‘shiny’ Interactive html with ‘plotly’, ‘Datatable’, ‘reactable’ Geo/Spatial coding and visualization in R Part IV is dedicated Advanced use of Data Science, Machine Learning, and AI and includes: Entity resolution and record linking in R Text Analysis in R Machine Learning and Modeling in R Computer vision and Deep learning in R Simulation and Optimization in R Operationalizing in-house built tools and models (could go in Part I) Part V contains the Tutorials developed by and for the community. These are: GCCode 101 Packages 101 R101: Building COVID-19 Tracker App from scratch Geo/Spatial coding and visualization with R. Part 1: Text Analysis with R. Part 1: and a number of short “How To: tutorials such as: Dual Coding - Python and R unite ! Working with ggtables Automate common look and feel of your ggplot graphs and others Part VI provides information about Shiny Web Apps developed by the community members. Finally, Appendix includes agendas, notes, and codes from the R4GC community “Lunch and Learn” meetups. "],["why-r.html", "1 Why R? 1.1 Top 10 R advantages for Data Science 1.2 Tackling the limitations of R 1.3 R vs. Python", " 1 Why R? R is one of the fastest growing programming languages and environment for data science, visualization and processing. R integrates well with Python and other free and commercial Data Science tools. It can also do something that other tools cannot and is very well supported by growing international community. It also comes with RStudio - a free Integrated Development Environment (IDE) that is now supported by most GC Agencies and Departments, and that is becoming one of the main tools for data related problems worldwide. For Microsoft data users, anything you do with Excel, Access, Power BI, you can also do with R and RStudio. 1.1 Top 10 R advantages for Data Science A quick review of the presentations made at the 2021 International Methodology Symposium showed that about one third of projects presented at the symposium were done using R and RStudio. If counting the percentage of projects dealing with data visualization, including geo/spatial mapping, then this number becomes close to two thirds of all presented projects. Clearly, even though Python remains the most frequently used language for machine learning and complex data analysis tasks, R has become de-facto the language of choice in many government departments when it comes to developing interactive reports, web applications and complex visualizations, thanks to such its popular packages as “rmarkdown”, “ggplot” and “shiny”. Other advantages of R highlighted at the Symposium include: common tidy data approach shared across all R packages; peer-reviewing and curation of packages by CRAN (Comprehensive R Archive Network), which is facilitated through the “devtool” R package that is specifically designed for this purpose; and RStudio-led movement for R education and deployment. All of these are in contrast to the ‘wild-west’ development of Python packages (which is a popular expression even among Python users), and are very important for enabling collaborative development of data science codes and knowledgebase. To summarize, below are our own Top 10 reasons to use R for Data Science - filtered and refined by the members of this community. Advanced graphics with ggplot2 and its extensions Automated report/tutorials/textbooks generation with RMarkdown Streamlined package development with devtools Streamlined Interactive interfaces and dashboards development and deployment with Shiny “Best for geocomputation”* Common tidy design shared across packages Curated peer-tested repo of packages at CRAN RStudio IDE (Integrated Development Environment) on desktop and cloud (rstudio.cloud) Full support and inter-operability with Python from the same IDE Global RStudio**-led movement for R education and advancement (rstudio.com) https://geocompr.robinlovelace.net/intro.html#why-use-r-for-geocomputation (also https://geocompr.robinlovelace.net/preface.html#why-r) RStudio is a free suit of tools and education resources to program in R developed by a Public Benefit Corporation, which also provides free on-cloud IDE for coding data science projects in R and other languages 1.2 Tackling the limitations of R The main deficiency of R (in particular, when compared to Python) is that many R functions and packages are not developed to be memory- or processing time- efficient, and “by default”, i.e., unless special care is taken in developing the code, most codes written in R are very slow and consume prohibitively large amount of memory, making it often impossible to run data processing codes on ordinarily laptops (with not more than 16 GB of RAM) such as those used by majority of GC employees. This is because all variables in R, including data array and data frame variables (which are naturally very large) are passed to a function by copying the entire variable content from one memory location to another , and then copying it back after the function completes its operation. In other programming languages, such as Python, C++, or Java, such operations normally are not done by passing the entire object to a function, but rather by pasing only a pointer to (or memory address of) an object that needs to be processed by the function, which is much faster and does not consume a lot of memory. This deficiency however can be practically entirely eliminated, should the R code be developed using the “efficiency-by-design” methodology that is offered by the ‘data.table’ R package. This is why much emphasis in the R4GC community discussions is put on encouraging the community members to use ‘data.table’ class by default (or always) instead of base ‘data.frame’ class. Another deficiency of R is that object-oriented programming (OOP) is not native in R. There are a number of ways to implement an object in R - using S3, S4 and R6 classes, however each of them has its own limitations. This deficiency however is not critical, because fast and memory-efficient codes can still be developed with and without OOP, and, if needed, a portion of the OOP code can be also built in Python (or C++) and then used from within R using ‘Rcpp’ and ‘reticulate’ packages. 1.3 R vs. Python Main references: https://docs.rstudio.com/tutorials/user/using-python-with-rstudio-and-reticulate/ https://www.datacamp.com/community/tutorials/using-both-python-r The latter has also a nice summary of PROs vs. CONs for both languages, subjectively summarized by myself below: Python’s PROs: Object-oriented language (this is a big one for me) General Purpose , i.e. you can use elsewhere (e.g. with raspberry pi - www.raspberrypi.org, as I did for one of my daughters’ projects) Simple and easy to understand and learn (this could be subjective, but I would generally agree that R is not taught they way I personally would teach it, i.e. based on computer science principles, rather than on memorizing a collection of various heuristic tools and functions.) Efficient (fast) packages for advanced machine learning activities, e.g. tensorflow or keras (which you can use from R too, but it could be less efficient), also a large collection of audio manipulation / recognition (some of whicg I played with for one of my biometrics projects) Python CONs: Not really designed for advanced manipulation or visualization of data R’s PRO’s: It is designed specifically for data tasks CRAN provides &gt;10K peer-tested (!) packages for any data task you may think of . (I would also add - It also provides much great tools to get you OWN work be tested and featured one day in CRAN - which is what we are doing now at our Learn R Meet-ups!) ggplot2 graphics is unbeatable Capable of standalone analyses with built-in packages. (Anyone knows what it means??) R’s CON’s: Not the fastest or memory efficient (Hey- That’s without data.table package! I don’t think so,if you use data.table,properly) Object-oriented programming is not native or as easy in R, compared to Python. - Actually, I added this one. To me, this is one of main motivations to see how to use both Python and R, instead of R by itself. But for someone else, this could be not tie-breaker though "],["learn-r-right-way.html", "2 Learn R: Right way! 2.1 Intro 2.2 In which sense ‘Right’? 2.3 R101 from “R4GC Lunch and Learn” 2.4 Additional resources", " 2 Learn R: Right way! 2.1 Intro The number of resources and ways to learn R is overwhelming. Some of us have tried many of them until we found the best and the right ones. These are shared here. It is suggested to start learning R the “Right way”, as discussed below. 2.2 In which sense ‘Right’? Ok, perhaps the word “Right” is not right here… - What is right for someone, may not be right for someone else who learnt R another way. So, Let’s call it “DiffeRent” or “Non-tRaditional” way. It is indeed the best and right for us. And we hope hope that, even if it is not the right “right” for you, it is still “right” for you to help you further improve your R codings kills 2.3 R101 from “R4GC Lunch and Learn” Recommendations for R101 home-work: https://open-canada.github.io/UseR/resources.html The starters (for students coming from non computer science backgrounds): https://gorodnichy.github.io/r101/ 2.4 Additional resources 2.4.1 Ways to continue growing your R skills 2.4.1.1 Knowledge in Apart from reading and contributing to this R4GC Book and participating in our R4GC community meetups (which is naturally the best way :), you can : Ask questions (or seek for already many answers) at https://stackoverflow.com/. In fact, what a great option for you to save all the knowledgebase you acquire – Helping yourself, you also help others, and contribute to further improvement of many R packages ! browse and play with many open-source books (See next section) browse and play with many R blogs attend free RStudio monthly organized webinars: https://github.com/rstudio/webinars RStudio-Enterprise-Community-Meetup: https://www.meetup.com/RStudio-Enterprise-Community-Meetup - (NB: you may have to access it from your personal device) attend free annual RStudio organized conferences rstudio::conf https://resources.rstudio.com/rstudio-conf-2019 , 2020, 2021 etc 2.4.2 Selected presentations https://github.com/jennybc/debugging 2.4.2.1 Knowledge out See next chapter for options wher you can submit or present your work, get it reviewed and published "],["great-open-source-textbooks.html", "3 Great Open Source Textbooks 3.1 By presentation 3.2 By Topic", " 3 Great Open Source Textbooks The R4GC book is inspired by many great open-source textbooks built using bookdown R package. These are listed below. Some of these are forked into https://github.com/open-canada/ to allow further testing and editing of the codes there For textbooks specific to each discussion topic in The R4GC book, please see the corresponding discussion topic chapters. For a much larger collection of bookdown books see: https://www.bigbookofr.com/. Source: https://github.com/open-canada/BigBookofR https://bookdown.org/ 3.1 By presentation 3.1.1 In two-column format https://bookdown.org/yihui/bookdown/ (https://bookdown.org/yihui/rmarkdown/bookdown-output.html#bookdown-output) https://bookdown.org/yihui/rmarkdown-cookbook/ https://rstudio4edu.github.io/rstudio4edu-book/. Source: https://github.com/open-canada/rstudio4edu-book https://clauswilke.com/dataviz. Source: https://github.com/open-canada/dataviz https://csgillespie.github.io/efficientR/ https://www.datascienceatthecommandline.com/1e/ https://moderndive.com/ - https://github.com/moderndive/ModernDive_book https://smltar.com/ Supervised Machine Learning for Text Analysis in R EMIL HVITFELDT AND JULIA SILGE 2021-10-17 https://bookdown.org/ejvanholm/Textbook/ https://bookdown.org/igisc/EnvDataSci/ Introduction to Environmental Data Science https://bookdown.org/sunboklee/intror_ewha/ R for Solving Social Problems https://bookdown.org/aclark/chess/ https://bookdown.org/selesnow/build_telegram_bot_using_r/ Разработка telegram ботов на языке R / Development of Bots in R (In Russian) 3.1.2 In three-column format On Shiny: https://mastering-shiny.org/preface.html https://engineering-shiny.org/ https://unleash-shiny.rinterface.com/ From Hadley: https://r4ds.had.co.nz/ https://adv-r.hadley.nz/ https://r-pkgs.org/ https://geocompr.robinlovelace.net/ 3.2 By Topic 3.2.1 Introductory and General TBA 3.2.2 Specialized TBA "],["great-open-source-tutorials.html", "4 Great Open Source Tutorials 4.1 From RStudio 4.2 From Data Carpentry 4.3 More from GitHub", " 4 Great Open Source Tutorials 4.1 From RStudio https://github.com/rstudio/webinars “Data Science Course in a Box” course: https://github.com/rstudio-education/datascience-box Data-sets: https://github.com/rstudio-education/dsbox) R for Data Science Instructor’s Guide https://github.com/rstudio-education/r4ds-instructors A guide to some of the most useful R Packages that we know about, organized by their role in data science. - https://github.com/rstudio/RStartHere https://github.com/rstudio/cheatsheets 4.2 From Data Carpentry Many free open source Lessons and Workshops are developed by Data Carpentry. The sources for many of them can be found at https://github.com/search?q=topic%3Ar+org%3Adatacarpentry . Some are listed below. datacarpentry/R-ecology-lesson Data Analysis and Visualization in R for Ecologists datacarpentry/r-raster-vector-geospatial Introduction to Geospatial Raster and Vector Data with R datacarpentry/r-socialsci R for Social Scientists datacarpentry/semester-biology data-science r sql biology spatial-data teaching-materials data-carpentry datacarpentry/rr-organization1 The Organization lesson for the Reproducible Science Curriculum r english on-hold lesson reproducibility data-carpentry carpentries project-organisation datacarpentry/r-intro-geospatial Introduction to R for Geospatial Data datacarpentry/rr-automation Resources for automation tutorials datacarpentry/genomics-r-intro Intro to R and RStudio for Genomics datacarpentry/rr-intro Introduction materials for Reproducible Research Curriculum datacarpentry/rr-literate-programming Repository for lesson materials on Literate Programming 4.3 More from GitHub "],["events-and-forums-for-r-users.html", "5 Events and forums for R users 5.1 From RStudio 5.2 R blogs 5.3 R conferences 5.4 Related journals: 5.5 RElated conferences 5.6 Related communities in GC", " 5 Events and forums for R users 5.1 From RStudio 5.1.1 https://resources.rstudio.com. Webinars 5.1.2 RStudio Community Meetup Another great meetup opportunity: https://www.meetup.com/RStudio-Enterprise-Community-Meetup NB: you may be able to access it from GC network. Each meetup is dedicated to a specific topic, following which they post many Q&amp;A at https://community.rstudio.com/ 5.2 R blogs https://rpubs.com 5.3 R conferences (from https://rviews.rstudio.com/2021/03/03/2021-r-conferences) Cascadia RConf 2021 (June 4 - 5), a jewel of a regional R conference for its first three years, was canceled in 2020. It is back this year as a virtual event. The Call for Presentations is open. useR! 2021 (July 5 - 9) has an outstanding lineup of keynote speakers. The program is very likely to make US based attendees night-owls EARL Conference 2021 (September 6 - 10), the premier R in industry event, will be online this year. The call for abstracts is already open. 5.4 Related journals: This is where you can submit or present your data science work. https://peerj.com/articles/?q=data https://earlconf.com/#about: The Enterprise Applications of the R Language Conference (EARL) https://odsc.com/boston/: Data Science Conference &amp; Expo https://journals.plos.org/plosone/search?filterJournals=PLoSONE&amp;q=data+science (research by the US Department of Homeland Security is published there) See also (from http://charteredabs.org/academic-journal-guide-2015-view/ (Rank 4-3)) Management Science IEEE Transactions on Systems, Man, and Cybernetics: Systems (formerly “IEEE Transactions on Systems, Man and Cybernetics - Part A: Systems and Humans”) Annals of Operations Research IEEE Transactions on Cybernetics (formerly “IEEE Transactions on Systems Man and Cybernetics Part C (Applications and Reviews)”) INFORMS Journal on Computing OR Spectrum Transportation Science Computational Statistics &amp; Data Analysis 5.4.1 Academic Journals: Operations Research (Informs): https://pubsonline.informs.org/journal/opre https://www.scirp.org/journal/jdaip/ - Journal of Data Analysis and Information Processing 5.5 RElated conferences 5.5.1 Non-academic 5.5.2 Academic Conferences: Canadian AI Conference - https://www.caiac.ca/en/conferences Otheer AI conferences 5.5.3 IEEE Conferences IEEE BigData IEEE International Conference on Technologies for Homeland Security HST 5.6 Related communities in GC Roughly sorted by the level of group activity 5.6.1 GCConnex (GC only): https://gcconnex.gc.ca/groups/profile/5394852/data-science-goc https://gcconnex.gc.ca/groups/profile/56632124/statcan-data-science-communities-of-practice-hub https://gcconnex.gc.ca/groups/profile/53857931/applied-machine-learning-ml-for-text-analysis-community-of-practice-cop https://gcconnex.gc.ca/groups/profile/22346843/big-data-community https://gcconnex.gc.ca/groups/profile/39621554/data-visualization-resources https://gcconnex.gc.ca/groups/profile/24345174/data-visualization https://gcconnex.gc.ca/groups/profile/47035648/machine-learning-in-remote-sensing-cop https://gcconnex.gc.ca/groups/profile/24825105/data-analytics-coalition https://gcconnex.gc.ca/groups/profile/47035648/machine-learning-in-remote-sensing-cop https://gcconnex.gc.ca/groups/profile/19758048/analytics-mining-and-hypothesis-testing https://gcconnex.gc.ca/groups/profile/62219803/artificial-intelligence-and-data-science-group https://gcconnex.gc.ca/groups/profile/30787891/digital-academy https://gcconnex.gc.ca/groups/profile/36236376/candev-data-challenge- https://gcconnex.gc.ca/groups/profile/4474153/data-analytics-working-group-dawg https://gcconnex.gc.ca/groups/profile/34024870/welcome-to-r-canadian-government (not active) 5.6.2 GCcode (GC only): https://gccode.ssc-spc.gc.ca/r4gc https://gccode.ssc-spc.gc.ca/DSCV 5.6.3 GCcollab (public with login): https://gccollab.ca/groups/profile/778815/eneccc-network-of-experts-and-researchers-in-data-science-nerdsfrlabo-de-donnu00e9es https://gccollab.ca/groups/profile/3465987/enswam-support-for-wildlife-analysis-and-monitoringfr https://gccollab.ca/groups/profile/18873/enopen-governmentfrgouvernement-ouvert https://gccollab.ca/groups/profile/7071541/endata-engineering-challenges-and-solutions (#GCData2021 conference workshop) More GCcollab groups are listed at https://wiki.gccollab.ca/The_Square/GCcollab_Groups 5.6.4 GCwiki (public): https://wiki.gccollab.ca/The_Square/Data_Science 5.6.5 GitHub (public): https://github.com/open-data https://github.com/canada-ca https://github.com/PatLittle 5.6.6 Other Canada groups https://code.open.canada.ca/en/open-source-softwares.html "],["open-policies.html", "6 Open government policies 6.1 Open Source 6.2 Open Science", " 6 Open government policies 6.1 Open Source “Directive on Service and Digital” – Appendix A: https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=32602. Open Sourcing GC Code https://canada-ca.github.io/ofd-joep/assets/pdf/Open%20Source%20Code%20Calvin%20Rodo.pdf https://github.com/canada-ca/Open_First_Whitepaper/blob/master/en/4_Open_Source_Software_Contribution.md#releasing-open-source-software-code https://code.open.canada.ca/open-source-code.html &lt;– broken link Government of Canada Strategic Plan for Information Management and Information Technology 2017 to 2021 https://www.canada.ca/en/treasury-board-secretariat/services/information-technology/strategic-plan-2017-2021.html#toc6-2 Guidance: When code should be open or closed https://www.gov.uk/government/publications/open-source-guidance/when-code-should-be-open-or-closed 6.1.1 Open government A Framework for Implementing Open-by-Default with Federal Government Science January 4, 2021 https://www.ic.gc.ca/eic/site/063.nsf/eng/h_98201.html Directive on Open Government https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=28108 6.2 Open Science Roadmap for Open Science https://www.ic.gc.ca/eic/site/063.nsf/eng/h_97992.html 6.2.1 Scientific Integrity Model Policy on Scientific Integrity https://www.ic.gc.ca/eic/site/063.nsf/eng/h_97643.html "],["use-r-efficiently-with-data.html", "7 Use R efficiently with data.table! 7.1 data.table vs. dplyr 7.2 Extensions of data.table", " 7 Use R efficiently with data.table! ## TL;DR For any code you do (ie, by default) your first lines of code should be: The data.table package developed by Matt Dowle is a game changer for many data scientists Learn about it… and use it always, by default: library(data.table) dtIris &lt;- data.table(iris) # or df &lt;- iris; dtIris &lt;- setDT(df) Where to learn: https://github.com/Rdatatable/data.table https://github.com/chuvanan/rdatatable-cookbook http://r-datatable.com (https://rdatatable.gitlab.io/data.table/) https://www.datacamp.com/courses/time-series-with-datatable-in-r https://www.datacamp.com/courses/data-manipulation-in-r-with-datatable https://github.com/Rdatatable/data.table/wiki/Articles https://rpubs.com/josemz/SDbf - Making .SD your best friend 7.1 data.table vs. dplyr data.table (Computer language) way vs. dplyr (“English language”) way The best: No wasted computations .No new memory allocations. dtLocations %&gt;% .[WLOC == 4313, WLOC:=4312] No new memory allocations, but computations are done with ALL rows. dtLocations %&gt;% .[, WLOC:=ifelse(WLOC==4313, 4312, WLOC)] The worst: Computations are done with ALL rows. Furthermore, the entire data is copied from one memory location to another. (Imagine if your data as in 1 million of cells, of which only 10 needs to be changed !) dtLocations &lt;- dtLocations %&gt;% mutate(WLOC=ifelse(WLOC==4313, 4312, WLOC)) NB: dtLocations %&gt;% . [] is the same as dtLocations[]. so you can use it in pipes. 7.2 Extensions of data.table There’s considerable effort to marry data.table package with dplyr package. Here are notable ones: https://github.com/tidyverse/dtplyr (Version: 1.1.0, Published: 2021-02-20, From Hadley himself - I found it quite cumbersome still though…) https://github.com/asardaes/table.express (Version: 0.3.1 Published: 2019-09-07 - somewhat easier?) https://github.com/markfairbanks/tidytable (Version: 0.6.2 Published: 2021-05-18 - seems to be the best supported of the three?) "],["python-and-r-unite.html", "8 Python and R unite!", " 8 Python and R unite! Check out our latest Lunch and Learn Meetup : ‘Lunch and Learn’ Meetup: Dual Coding - Python and R unite! : GCcollab It shows how to Execute R from Python and Vice Versa, inspired by this blog: this https://www.kdnuggets.com/2015/10/integrating-python-r-executing-part2.html The used code is available from GCCode: https://gccode.ssc-spc.gc.ca/r4gc/resources/howto "],["from-excel-to-r.html", "9 From Excel to R", " 9 From Excel to R There was a keen interest expressed at last Friday meetup on transitioning from Excel to R. Incidentally, there was an RStudio Community Meet-up focused exactly on this topic: Meetup: Making the Shift from Excel to R: Perspectives from the back-office Many Q&amp;A from this meetup are posted here: https://community.rstudio.com/t/meetup-making-the-shift-from-excel-to-r-perspectives-from-the-back-office/100467 Below are listed some. There’s also a link to a video-recording of it! (at link above) What was the most common problem when moving from Excel to R? [Excel -&gt; R Meetup Q&amp;A] R Markdown vs R Scripts in Enterprise Workflows [Excel -&gt; R Meetup Q&amp;A] What sort of packages did you use for reconciliation? [Excel -&gt; R Meetup Q&amp;A] What is the best way to share the results of an analysis that you’ve made in R? [Excel -&gt; R Meetup Q&amp;A] How do you get buy-in transitioning from Excel to R? [Excel -&gt; R Meetup Q&amp;A] How do you get buy-in from the IT team around R package security concerns? [Excel -&gt; R Meetup Q&amp;A] How do you move data from tricky worksheets into R? [Excel -&gt; R Meetup Q&amp;A] With so many ways of doing the same things, how do you find the best way to do something? [Excel -&gt; R Meetup Q&amp;A] This dictionary of Excel/R equivalent was very useful is finding a starting point for common functions: https://paulvanderlaken.com/2018/07/31/transitioning-from-excel-to-r-dictionary-of-common-functions/ For people who are looking for something more comprehensive, this website is very useful: https://rstudio-conf-2020.github.io/r-for-excel/ Pour ma part, j’adhère à l’approche proposée par The Carpentries, soit l’utilisation d’Excel pour la saisie de données et une partie du contrôle de la qualité. Par la suite, les données sont exportées en csv pour être importées dans R. "],["reading-various-kinds-of-data-in-r.html", "10 Reading various kinds of data in R 10.1 readxl and xlsx 10.2 Discussion", " 10 Reading various kinds of data in R There are many kinds of data you want to read - and you want to them efficiently (i.e. , automatically and fast): badly formatted data, sparse data, distributed “big” data just very large and very very large MS excel, MS Words from clouds: AWS, MS Azure etc pdf, html zip files google docs, google sheets GCdocs and from other GC platforms (that was one of the questions at our Friday’s R meetup), and, from web pre-formated other IoT and web-crawling 10.0.0.1 fread Our favourite methods for reading / writing “regular” .csv files has been ‘data.table::fread() and fwrite()’ - the fastest and automated in many ways. 10.0.0.2 vroom Now there’s another one - with package ‘vroom’ - https://cran.r-project.org/web/packages/vroom/vignettes/benchmarks.html 10.0.1 rio library(rio) install_formats() See: https://www.computerworld.com/article/2497164/business-intelligence-beginner-s-guide-to-r-get-your-data-into-r.html 10.1 readxl and xlsx For reading Excel files, you can use readxl. You would like to be able to import a set of columns formed by non-contiguous columns of a sheet (something possible to select in the newer versions of Excel using data queries). For writing Excel files, you can use xlsx, espcially, if you need to be able to write multiple sheets in a file. 10.2 Discussion The analyst should, actually, never stick to one solution but rather adapt to the needs of the project. For every format that is good and efficient with big data, you gain either 1) get manipulation overhead that does not make sense when manipulating small datasets, and they can end up slower than even dataframes in that case on small data but hundreds of times faster in big data (e.g. feather), or 2) need to wait forever and lose storage space for nothing (parquet) if the data is not big enough. Yet, if you found the right solution for every size and need, it will make a world of difference. … The example below does a comparison of some popular formats when used with Pandas (Python). You will get similar results in R https://towardsdatascience.com/the-best-format-to-save-pandas-data-414dca023e0d … One of the options, if your are only playing locally and not in the cloud, is using the ‘feather’ format with ‘sql.’ If you need to extract data from a database and do more advanced data engineering without loading data in your RAM, you need SQL to prepare the extraction and do basic to advanced manipulation (SQL is Turing-complete, eh). For more advanced and permanent transformations to the data, you need stored procedures (SQL again). And if you play in the cloud, this is even more essential. For example, in AWS, you can create user-defined functions in Redshift using Python and Postgres SQL, but not R. All manipulation needs to be done in SQL, and Python can be used for other purposes such as calculations and fuzzy matching. You can still use R in the rebranded Jupyter notebooks (Sagemaker in AWS, Azure Notebooks in Azure), but R is not as widely compatible in other cloud applications as SQL and Python. - [ PD: But you can absolutely use R in AWS for ETL. In fact you could even set up API endpoints via plumbr, there’s a whole AWS tutorial that deals with this issue] References: https://github.com/pingles/redshift-r/ Provides a few functions to make it easier to access Amazon’s Redshift service from R. http://www.rforge.net/RJDBC/index.html install.packages(“RJDBC”,dep=TRUE) RJDBC is a package implementing DBI in R on the basis of JDBC. This allows the use of any DBMS in R through the JDBC interface. The only requirement is working Java and a JDBC driver for the database engine to be accessed. feather (for larger than gigb): https://blog.rstudio.com/2016/03/29/feather/ parquet ( for verrrrry large files) https://campus.datacamp.com/courses/introduction-to-spark-with-sparklyr-in-r/case-study-learning-to-be-a-machine-running-machine-learning-models-on-spark?ex=4 Conclusions: As a side note on size, speed, and performance : it all depends on what you do, the delays, and the cost. For example, if you use the cloud: If your data is going to be queried very often, so you have large volumes of data that would be scanned, move your processing to a runtime-billed tool (e.g. Redshift in AWS) rather than a data-billed tool (e.g. Athena in AWS). Otherwise, your cost may increase exponentially if users can survey data freely from, say, Tableau dashboards without caring for the actual amount of data that is queried. So if the data is queried 24/24h, your cost is stable and won’t increase with volume. If you may scan large volumes once or twice a day, then you would have to compare the costing options. If the costing model is incremental by runtime and you have very large amounts of data that you need to query quickly, then it would be best to use columnar formatted tables such as parquet. There is a cost and delay involved for the conversion, and you need much more storage because of the flattened structure, so storage will be more expensive (especially considering that you clone your original data and use at least twice the space then). However, queries will fly, and the cost of computation will be much smaller thereafter. For occasional queries, a data-billed tool would likely be the best option. If you want to prototype with small datasets, do not lose time with parquet… CSV is the worst format after Excel files (which need to be unpacked and repacked), in any scenario, but the time investment in time to convert data is not worth it at all. Data.table and DT will be your best friends in R. As for using SQL vs packages such as DPLYR, I mentioned a gain in performance, but be careful. If you use raw SQL, then you will see a big gain in performance. However, there are packages out there that translate SQL to R or Python interpretable code, and those will possibly be slower due to the interpretation layer. DPLYR, on the other hand, is quite efficient and well optimized. As usual, it depends on the packages. In R, the sqldf package should be good, if you want to try it out. "],["other-tips-for-efficient-coding-in-r.html", "11 Other tips for Efficient coding in R 11.1 Variable names ! 11.2 Code starter tricks 11.3 Efficient workflows 11.4 Object oriented programming in R 11.5 RStudio tricks", " 11 Other tips for Efficient coding in R 11.1 Variable names ! Variable names need to help you every time you see them! Examples: 11.1.1 Code formating Install ‘slyler’ package to have RStudio addin to automate formatting your code 11.2 Code starter tricks 11.2.1 Most important / useful libraries These are libraries / codes that one could use by default when starting a new code. # 0. General libraries and functions ---- # options(digits = 3); # 7 # options(max.print = 100) # 1000 # options(scipen=999); #remove scientific notation library(magrittr) # library(readxl) # library(readr) # library(stringr) ## library(tidyverse) # includes: readr ggplot2 stringr (which we use), dplyr tidyr tibble forcats purrr (may use later) and others - https://www.tidyverse.org/packages/ # library(dplyr) # or #library(dtplyr) # library(ggplot2) # library(lubridate, quietly=T) # to work work times and dates # options(lubridate.week.start = 1) library(data.table) # needs to be AFTER lubridate options(datatable.print.class=TRUE) # library(dygraphs) # library(plotly) # library(DT) `%ni%` = Negate(`%in%`) 11.3 Efficient workflows 11.3.1 Workflow: Data-first approach So, you found a new Open Data dataset. Great - now you can do something with it! This is how you start . 11.3.2 Workflow: Task/needs/algorithm-first approach TBA 11.4 Object oriented programming in R https://techvidvan.com/tutorials/r-object-oriented-programming/ 11.4.1 S3 11.4.2 R6 11.5 RStudio tricks 11.5.1 Coding online Platforms for coding R online https://rstudio.cloud/ (login required) - All in One place for learning and coding 11.5.1.1 Running multiple RStudio versions You want to be able to run multiple versions of RStudio in Windows? You can do with the following executable .bat script. # Run-RStudio-1.4.bat @echo off title Starting RStudio! echo Hello Dear, echo Starting RStudio 1.4 (from C:\\Users\\gxd006\\Downloads\\RStudio-1.4.1106\\bin\\) for you... C:\\Users\\abc123\\Downloads\\RStudio-1.4.1106\\bin\\rstudio.exe Set WshShell = CreateObject(&quot;WScript.Shell&quot;) WshShell.Run chr(34) &amp; &quot;C:\\Users\\gxd006\\Downloads&quot; &amp; chr(34), 0 Set WshShell = Nothing "],["using-r-with-gc-data-infastructure-gcdocs-aws-etc.html", "12 Using R with GC data infastructure (gcdocs, AWS, etc) 12.1 gcdocs", " 12 Using R with GC data infastructure (gcdocs, AWS, etc) 12.1 gcdocs Q: I’m wondering if anyone has had any success accessing data from GCDocs in your respective departments ? I believe that GCDocs is implemented across most (if not all) departments so wondering if there are any existing solutions to read/write data from it. Also wondering about whether any of you have had any luck accessing Microsoft 365 via R as well? I’ve had success with Microsoft365R package (https://github.com/Azure/Microsoft365R) from a personal point of view but it doesn’t play well with business accounts. "],["r-markdown-for-literate-programming-and-automated-reports.html", "13 R Markdown for literate programming and automated reports 13.1 Resources 13.2 Automated generation of multiple PDF files", " 13 R Markdown for literate programming and automated reports This discussion thread is for gathering knowledgebase related to R Markdown: https://rmarkdown.rstudio.com/ It can be used to generate reports, slides, websites, dashboards, shiny app, books, emails. It is the tools allows you to do literate programming, which – as defined by Donald Knuth - is the type of programming where human language is combined with computer language, making the code much easier understood by your colleagues and yourself and coding much more fun. 13.1 Resources Main reference: https://bookdown.org/yihui/rmarkdown/ A couple of great webinars from RStudio folks on advanced use of R Markdown - with lots of source codes: https://www.rstudio.com/resources/webinars/rethink-reporting-with-automation/ https://www.rstudio.com/resources/webinars/sharing-on-short-notice-how-to-get-your-materials-online-with-r-markdown/ Business Reports with R Markdown: https://github.com/cderv/meetup-2021-rmd-business-report R Markdown Taxonomy: https://github.com/jthomasmock/penguin-project 13.2 Automated generation of multiple PDF files Question: “Can we automatically generate multiple PDF files using R RMarkdown? E.g. 20 report cards in PDF format, each showing results for 50 different parameters of the analysis?” Answer: “Absolutely!” - This is what RMarkdown is developed for. Here’s a tiny R script example showing how to do it. Source: - https://stackoverflow.com/questions/67739377/passing-multiple-parameters-in-rmarkdown-document - https://stackoverflow.com/questions/60203785/using-multiple-params-in-rmarkdown-yaml-fields "],["ggplot2-and-its-extensions-for-data-visualization.html", "14 ggplot2 and its extensions for data visualization 14.1 Resources", " 14 ggplot2 and its extensions for data visualization Many come to R (from Python and other languages/ systems) mainly because of the advanced data visualization capabilities it offers. There are many of those, as are the resources. Share your recommendations and examples here. 14.1 Resources See: https://github.com/IVI-M/R-Ottawa/blob/master/resources.md Introduction to ggplot2 How to customize ggplot2 Top 50 ggplot2 visualizations ggplot2 quick reference sheet ggplot2 quick reference for colour names Modifying components of theme() in ggplot2 Colours in ggplot2, including colour-blind friendly palette Package for colour manipulation, including visualizing the effects of colour-blindness on colour palettes. https://cran.r-project.org/package=prismatic Dmitry Gorodnichy’s avatar By Dmitry Gorodnichy 2021-04-08 22:15Edit the discussion reply by Dmitry GorodnichyDelete the discussion reply by Dmitry GorodnichyLike the discussion reply by Dmitry Gorodnichy bookdown.org books on advanced visualization with ggplot and its extensions https://serialmentor.com/dataviz/ - https://github.com/clauswilke/dataviz. Fundamentals of Data Visualization. Claus O. Wilke https://github.com/jjallaire/dataviz-r OpenSDP Dataviz Tutorial (R) 14.1.1 Plotly + R Shiny https://socviz.co/ - Data Visualization. A practical introduction https://r-graphics.org/ R Graphics Cookbook, 2nd edition. Winston Chang. 2019-12-19 with Plotly in R Intro to Animations | R | Plotly - https://plotly.com/r/animations/ https://plotly-r.com/index.html https://plot.ly/r/animations/ "],["shiny-for-interactive-data-visualization-analysis-and-web-app-development.html", "15 Shiny for Interactive Data Visualization, Analysis and Web App development 15.1 Resources", " 15 Shiny for Interactive Data Visualization, Analysis and Web App development This discussion thread is dedicated to Shiny package - a RStudio-curated tool for developing and deploying Interactive Data Visualization and Analysis tools and applications. 15.1 Resources Kick start to Shiny - https://www.datacamp.com/courses/building-web-applications-in-r-with-shiny See also: Shiny - Gallery (rstudio.com) - https://shiny.rstudio.com/gallery/ https://engineering-shiny.org/ "],["interactive-outputs-in-r-plotly-datatable-reactable.html", "16 Interactive Outputs in R: plotly, Datatable, reactable 16.1 reactable", " 16 Interactive Outputs in R: plotly, Datatable, reactable This discussion is dedicated to tools to generate interactive graphs, tables, and other content without Shiny (which, as you know, requires a server to host your Shiny application and which for this reason cannot be easily shared with your clients, e.g. by email) Here are the most popular ones: https://rstudio.github.io/DT/ https://plotly.com/r/ and https://glin.github.io/reactable 16.1 reactable Check what kind of interactive coloured tables you can make with it: https://glin.github.io/reactable/articles/womens-world-cup/womens-world-cup.html "],["geospatial-coding-and-visualization-in-r.html", "17 Geo/Spatial coding and visualization in R 17.1 Resources 17.2 Federal Geospatial Platform 17.3 Tutorials 17.4 Dealing with memory issues 17.5 Canadian geo-data", " 17 Geo/Spatial coding and visualization in R 17.1 Resources There’s much effort across many GC departments to analyze and visualize geo-data. This discussion is the place to share your results, ideas or problems related to the problem. Below is a great resource to start, which also provides a nice explanation on why R is believed to be the best language to do this kind of work. Geocomputation with R, a book on geographic data analysis, visualization and modeling. The online version of the book is hosted at https://geocompr.robinlovelace.net and kept up-to-date by GitHub Actions 17.2 Federal Geospatial Platform From https://gcconnex.gc.ca/discussion/view/84695812/data-federation-federation-des-donnees Yukon’s open geospatial data is now searchable on the Federal Geospatial Platform (FGP) (https://gcgeo.gc.ca/) and on Government of Canada Open Maps Portal. Check it out ! With the addition of Yukon’s resources, the FGP now offers over 5,000 datasets available to discover and download, for public servants and Canadians, all in one location. Wondering how to create a map with your data? We can help you do so, from A to Z, at no cost. Contact us at nrcan.geoinfo.rncan@canada.ca 17.3 Tutorials Check codes and notes for the two Tutorials that we had on this subject this summer: https://gccode.ssc-spc.gc.ca/r4gc/resources/introSpatialAnalysis 17.4 Dealing with memory issues A blog post that illustrates a few ways to avoid overloading R’s memory when working with large spatial objects (here’s looking at you, 30-m land cover map of North America!). https://www.ecologi.st/post/big-spatial-data/ The two other posts on that blog also have some really nice tips for general R coding. 17.5 Canadian geo-data Useful code and R packages from public domain to work with Canadian geo-data. From https://mountainmath.ca - https://github.com/mountainMath/mountainmathHelpers - tongfen: Convenience functions for making data on different geometries, especially Canadian census geometries, comparable. - cancensus : R wrapper for calling CensusMapper APIs - cansim: Wrapper to access CANSIM data - CanCovidData: Collection of data import and processing functions focused on Canadian data "],["record-linking-and-other-data-engineering-tasks-in-r.html", "18 Record Linking and other Data Engineering tasks in R 18.1 demo", " 18 Record Linking and other Data Engineering tasks in R 18.1 demo See http://rcanada.shinyapps.io/demo and the #GCData2021 Data Engineering workshop presentation - for the backgrounder and the demonstration of various DE tasks and solutions. "],["text-analysis-in-r.html", "19 Text Analysis in R 19.1 Open source textbook 19.2 Plagiarism detection 19.3 results from International Methodology Symposium", " 19 Text Analysis in R https://gccollab.ca/discussion/view/7404441/text-analysis-in-r 19.1 Open source textbook https://smltar.com/ https://www.tidytextmining.com/ https://slcladal.github.io/topicmodels.html, https://slcladal.github.io/textanalysis.html Also, a list of related resources and codes for text mining (including Web Scraping) are collected here: https://github.com/gorodnichy/LA-R-text 19.2 Plagiarism detection Q: Any ideas/packages/resources (in R) for plagiarism detection? A: A good place to start is the “stylo” package (https://github.com/computationalstylistics/stylo - R package for stylometric analyses) which implements a wide variety of recent research in computational stylistics. Plagiarism detection is fraught (insert all of the usual ethical and computational caveats…), but stylo can help you identify passages that are stylistically unusual compared to the rest of the text. Unusualness definitely isn’t a proxy for plagiarism, but it’s a good place to start. Q: Is this focused on English language text? Are there lexicons or libraries for comparison within other languages (e.g., French)? A: Stylo works well with quite a few non-English languages. French, for example, is supported, as are a number of languages with non-Latin alphabets like Arabic and Korean. 19.3 results from International Methodology Symposium Two presentations at International Methodology Symposium were about Text Analysis with R, with great ideas from both: 11B-4 by Andrew Stelmach from StatCan: used library(fastText) - a very powerful package from facebook AI team for efficient learning of word representations and sentence classification. 11B-2 by Dave Campbell from Carleton U: used the approach that we discussed at L&amp;L on October 9 (based on bag of words cosine distance / correlation) for matching beer products description - https://gccode.ssc-spc.gc.ca/r4gc/resources/text/), but addtionally applied SVD (singular value decomposition) to reduce comparison to the most imporant words, thus reducing significantly the dimension and speed. You can find their decks here: https://drive.google.com/drive/folders/1TfuNmG3V8IEKDNNTcMZz7_YCKgqVVBju "],["statistical-tests-and-mixed-effects-analysis.html", "20 Statistical tests and mixed-effects analysis", " 20 Statistical tests and mixed-effects analysis TBA "],["machine-learning-and-modeling-in-r.html", "21 Machine Learning and Modeling in R 21.1 Resources 21.2 Additional references", " 21 Machine Learning and Modeling in R 21.1 Resources Below are most popular textbooks for Machine Learning and Modeling in R. Also see Discussion on Text Mining (https://smltar.com/ and https://www.tidytextmining.com/) This one is used in many University Machine Learning courses (e.g. in University of Arizona and many others in USA): An Introduction to Statistical Learning with Applications in R https://www.statlearning.com/ ( https://web.stanford.edu/~hastie/ISLR2/ISLRv2_website.pdf ) These are on Tidy models (most come with source codes): https://www.tidymodels.org/books/ https://www.tmwr.org/ - TIDY MODELS WITH R https://bookdown.org/max/FES - Feature Engineering &amp; Selection https://moderndive.com/. Statistical Inference via Data Science 21.2 Additional references References https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf -http://www2.math.uu.se/~thulin/mm/breiman.pdf "],["deep-learning-and-computer-vision.html", "22 Deep Learning and Computer vision", " 22 Deep Learning and Computer vision This discussion thread on Deep Learning with Tensorflow and Keras inR (https://tensorflow.rstudio.com/) Learn and Apply Artificial Neural Networks (aka Deep Learning) with Keras/Tensorflow in R/RStudio, Using complete prewritten codes, your own data, and data.table package: https://github.com/gorodnichy/LA-R-KerasNN 22.0.0.1 Deep Learning using the h2o package in R https://github.com/h2oai/Deep-Learning-with-h2o-in-R "],["simulation-and-optimization.html", "23 Simulation and Optimization", " 23 Simulation and Optimization There are a number of R packages developed for complex processes simulations and optimization problems, including simulation of queueing processes and resource or performance optimization problems They were used in the research on predicting and optimizing Border Wait Time at Canadian border. The codes for it and the research article are available at GCcode (search “border”) or by contacting Dmitry Gorodnichy. "],["gccode-101.html", "24 GCCode 101 24.1 TL;DR 24.2 Step 00: Connecting to GCCode and installing required soft. 24.3 Step 0: Configuring Windows, Git and GitLab (tokens) 24.4 Step 1: Find (or create) a GitLab project you want to contribute to. 24.5 Step 2: Using Branches (optional) 24.6 Step 3: GCcoding from RStudio 24.7 Related GC discussions and links:", " 24 GCCode 101 title: “gccode101: working with GCCode” subtitle: (With focus on how to do it using RStudio) date: September 2020 The information presented here includes only open public domain knowledge and does not include specific details related to operation of each GC department. Full tutorial and relatred Q&amp;A are available at https://gccode.ssc-spc.gc.ca/r4gc/resources/gccode101 24.1 TL;DR [One time action per life time] Make sure you have RStudio and git installed on your local machine: eg from Anaconda - Ask your IT to help you. [One time action per project] Go to GCCollab and create a new repo there (it can be left empty or just add README.md there) or select the existing one where you want to work on: eg https://gccode.ssc-spc.gc.ca/r4gc/gc-packages/packages101 Generate Access Token (from Setting in left panel) or request one for a repo of which you are not the owner. It will look something like this: LNwVUF5YGnF-6x5fsnJ- Open Windows PowerShell (or cmd), go to directory where you want to clone your repo (eg. cd C:_CODES_packages) and run this command: git clone --progress https://oauth2:LNwVUF5YGnF-6x5fsnJ-@gccode.ssc-spc.gc.ca/r4gc/gc-packages/packages101 gc-packages101. Close it - you wont need it again! You can check - your new directory contains .git/ folder ! (This is where your credentials for GCCollab are stored ) Open RStudio and create New project there. You have two options. In both cases, You’ll see the GIT button on top, once you finish and reload your project with RStudio, which means you are all set now and can start modifying / building your code! Option A (To build a new R package): Choose New project -&gt; New Directory -&gt; New Project (with Name of your package, eg caPSES). Leave “Create a git directory box UNCHECKED. Once it is created, MOVE the entire content of this new package folder to the directory that you cloned in previous step (which contains .git/ folder), or vise versa just move .git/ folder from the cloned directory to your new package directory) Option B (for any other project): Choose New project -&gt; Existing directory -&gt; point to your new cloned directory. That’s it. [Every time you make changes in project] We recommend to always pull first (to avoid conflicts later)- from Git menu button Make changes, open commit window, describe them, commit them, push them back to repo Enjoy the rest of your day ! More details from our fRiday’s Lunch and Learn discussions follow below. 24.2 Step 00: Connecting to GCCode and installing required soft. “Connecting” means being able to pull a repository to your local (gc-network connected) machine, modify code there (in RStudio is the easiest), commit your changes, and pull it back to GCCode. Before doing that you need the following programs installed on your local (gc-network connected) machine, Below (*) indicates options that have been tested as most efficient R: from Anaconda from CRAN*: R version 4.0.2 (2020-06-22): As of Sept 2020, we have right to install packages directly from CRAN. So you can do library(installr); updateR() RStudio: From Anaconda Prompt in new environment*: conda create -n e2020.03.02-markdown_issues mro-base rstudio (replace mro-base rstudio(replacee2020.03.02-markdown_issueswithYOUR_NEW_ENVIRONMENT_NAME`) (This will create a shortcut (R) on desktop). - old: Version 1.1.456 – © 2009-2018 RStudio, Inc. Git: From Anaconda Prompt*: conda install git (or you can install in new environment e2020.03.02-markdown_issues) From Anaconda Prompt: conda install m2-git (I installed in new environment e2020.07.21_mintty) Q: where is git.exe actually located in c: drive ? cd \\ . A: C:.21_mintty Check with IT - from web: https://git-scm.com/download/win (Git for Windows Portable (“thumbdrive edition”) - 64-bit Git for Windows Portable. NB: it’s not accessible from CBSA network) Command windows (where you can run git commands): Windows cmd (it may or may not work there for your machine) Anaconda prompt: this does not take all shell commands) mintty* ( from www.msys2.org), install: conda install m2-base (creates ~/anaconda3/Library/mingw64 directory, git.exe installed with m2-git will be placed in /bin there). You can then run it from conda terminal: mintty Run which git (linux style from mintty) or where git(windows style from mintty) to find out path to git.exe Note how Linux-like file system is mapped to Windows’ one below: $ where git: C:.exe $ which git: /usr/bin/git Windows PowerShell: works well but does not take all linux commands , e.g it does not know which/where, ls -a) RStudio Terminal ** : it runs from git in your active environment from which you started RStudio. This allows to use different git.exe settings or executables. There are additional recommended packages for efficient source control and collaborative code development, which however can be learnt later, such as : renv docker devtools 24.3 Step 0: Configuring Windows, Git and GitLab (tokens) 1: Edit environment variable for your account (Search “env”) and set HOME to /c/users/gxd006/ (replace gxd006 with your user id). - This will become your home directory ~ for mintty and this is where your .gitconfig file will reside for git used in mintty! - needed for next step below Test it: $ echo $HOME: /c/Users/gxd006/ 2: Edit .gitconfig file as follows (note, it maybe invisable to your OS. The easiest way to open/edit it is using RStudio. ) Alternatively, you can view/edit using build-in vim editor: vim .gitconfig or by running git config --global -e. - Three vim main commands: - ESC a: (insert text after cursor), - ESC: wq (save and exit), - ESC: q! (dont save and exit) NB: if you run terminal from RStudio (rather than from mintty), then git config --global -e will open .gitconfig file from where it is found using where git [user] name = Your Name email = your.email@cbsa-asfc.gc.ca [http] proxy = &quot;http://proxy.omega.dce-eir.net:8080&quot; NB: if you do not do that, you’ll be this getting error: fatal: unable to access &#39;https://gccode.ssc-spc.gc.ca/super-koalas/shared-code/&#39;: Failed to connect to gccode.ssc-spc.gc.ca port 443: Timed out 3: Decide how/where you will organize your gccode on your machine. This is how I converged (after many iterations) to organize my projects - see file_structure.md 4: If you dont want to be typing your login id/password everytime you connect to GCCode (which I’m sure you dont:), read this article: https://knasmueller.net/gitlab-authenticate-using-access-token, and create your new personal access token there (which will look something like tjxrg3GyUQJJDMaA6LfHA) 24.4 Step 1: Find (or create) a GitLab project you want to contribute to. Lets say, you want to contribute to this project: https://gccode.ssc-spc.gc.ca/r4gc/resources/gccode101 1.1: Go to ~/_CODES/GCCodes (this where you keep all your GCCodes projects), and run from cmd terminal, or Anaconda prompt, or mintty: CORRECTION: Q: Currently works from conda or mintty termminal only. How to make git calleable from Windows cmd? I changed PATH to add a directory to C:\\Users\\gxd006\\anaconda3\\Library\\bin it did not help (base) C:\\Users\\gxd006&gt;which git /usr/bin/git vs. H:\\&gt;git &#39;git&#39; is not recognized as an internal or external command, operable program or batch file. From Anaconda prompt, or mintty: git clone --progress https://gccode.ssc-spc.gc.ca/r4gc/resources/gccode101 r4gc_gccode101 or better (if you set a personal token - see Step 0.4 above) git clone --progress https://oauth2:tjxrg3GyUQJJDMaA6LfHA@gccode.ssc-spc.gc.ca/r4gc/resources/gccode101 r4gc_gccode101 Now you can go to the created directory r4gc_gccode101 and do something there, either from command line or directly from RStudio. 24.4.1 1.2 Using Command Line Push a new file cd existing_folder touch README.md git add README.md git commit -m &quot;add README&quot; git push -u origin master Push an existing folder cd existing_folder git init git remote add origin https://gccode.ssc-spc.gc.ca/r4gc/resources/gccode101 git add . git commit -m &quot;Initial commit&quot; git push -u origin master Push an existing Git repository cd existing_repo git remote rename origin old-origin git remote add origin https://gccode.ssc-spc.gc.ca/r4gc/resources/gccode101 git push -u origin --all git push -u origin --tags 24.4.2 1.2 In RStudio Recommended - see below 24.5 Step 2: Using Branches (optional) It is recommended that you create your own branch for every project where you want to contribute (e.g. I made branch ivi for myself) and do everything there. NB: you can also do it from RStudio or command line. git fetch git checkout ivi git checkout master git init . touch some.txt git add some.txt git commit git log git status git push For the rest of the presentation, we focus on using RStudio to do everything you need with GitLab in GCCode 24.6 Step 3: GCcoding from RStudio Configure git: in Global options Create new Project from existing directory (point to directory where you cloned GCCode repo) You’ll note that GIT button is visible now there ! (that’s because it knows that this directory is cloned from gitlab) Make some changes Click on GIT button menu -&gt; commit Check on file(s) you want to commit, Describe you change, click Commit, click push - Voila! Done. 24.7 Related GC discussions and links: https://gcconnex.gc.ca/discussion/view/64885627/downloading-r-packages-within-goc https://gcconnex.gc.ca/discussion/view/50817255/publishing-gc-code https://github.com/canada-ca/open-source-logiciel-libre https://canada-ca.github.io/open-source-logiciel-libre/en/guides/publishing-open-source-code.html https://isthisblockedinmydepartment.ca/ https://environments.rstudio.com/shared.html "],["packages-101.html", "25 Packages 101 25.1 Resources 25.2 * Setup 25.3 * Overall Workflow 25.4 * .Rbuildignore 25.5 * License: use_mit_license() 25.6 * DESCRIPTION 25.7 * NAMESPACE 25.8 * Examples and tests 25.9 .. in MY_CODES 25.10 * testthat 25.11 * Documentation 25.12 * Vignettes 25.13 Delivering package 25.14 Packaging and publishing w. pkgdown 25.15 (optional) Rtools", " 25 Packages 101 title: “How to convert your functions to package(s)” subtitle: “GC Lunch and Learn: R packages 101” author: Dmitry Gorodnichy and Joseph Stinziano gitlab: https://gccode.ssc-spc.gc.ca/r4gc/gc-packages/packages101 date: “March -June 2021” Taken from: https://gccode.ssc-spc.gc.ca/r4gc/gc-packages/packages101/-/blob/master/packages101.Rmd 25.1 Resources 25.1.1 GC groups and repos Discussions: https://gccollab.ca/groups/profile/7391537/enuse-rfruse-r https://gccollab.ca/groups/profile/7855030/enfriday-lunch-and-learn-r-meet-upsfr Codes: Packages101 repo: https://gccode.ssc-spc.gc.ca/r4gc/gc-packages/packages101 Related codes and resources: https://gccode.ssc-spc.gc.ca/r4gc 25.1.2 Related tutorials https://r-pkgs.org/ https://r-pkgs.org/vignettes.html https://fanwangecon.github.io/R4Econ/support/development/fs_packaging.pdf https://rstudio4edu.github.io/rstudio4edu-book/data-pkg.html - https://github.com/rstudio4edu/rstudio4edu-book http://www.danieldsjoberg.com/writing-R-packages - github.com/ddsjoberg/writing-R-packages 25.1.3 How to contribute Anyone: Fork Packages101 repo - modify - commit changes - push - submit request to merge Members of r4gc group: A token is generated to allow you to push/pull Packages101 repo. Use this line to push/pull from Packages101 repo: git clone --progress https://oauth2:tjxrg3GyUQJJDMaA6LfHA@gccode.ssc-spc.gc.ca/r4gc/gc-packages/packages101 r4gc_packages101 ======= 25.1.4 * R script to start: library(devtools) devtools::create(&quot;rCanada&quot;) ## if you are in /my_package devtools::create(&quot;../../rCanada&quot;) ## will it erase it,if I lready have it? &gt; #or usethis::create_package(&quot;../r4gc/packages/rCanada2&quot;) library(roxygen2) ## library(testthis).&lt;- we dont use this!Dont confuse it with library(testthat) ?? library(testthat) ## do we need it? library(usethis) ## https://github.com/r-lib/usethis usethis::use_testthat() ## use_testthat() use_news_md() use_test(&quot;iviDT&quot;) x &lt;- 1 y &lt;- 2 use_data(x, y) use_vignette(name=&quot;my_vignettes&quot;) # use_vignette(name=&quot;data_linking&quot;) use_package(&quot;data.table&quot;) ## &gt; use_package(&quot;data.table&quot;) ## √ Adding &#39;data.table&#39; to Imports field in DESCRIPTION ## * Refer to functions with `data.table::fun()` use_package(&quot;magrittr&quot;) use_package(&quot;data.table&quot;) use_package(&quot;lubridate&quot;, type=&quot;Imports&quot;) ## how about order ?! lubridate must be after data.table ! use_package(&quot;stringr&quot;) use_package(&quot;IVIM&quot;) ## To update .Rd files in ./man, run: devtools::document() ## Warning: The existing &#39;NAMESPACE&#39; file was not generated by roxygen2, and will not be overwritten. ## So delete it, and then it will be created 25.1.4.1 To be discussed Q: When I Clean and Rebuid: ????! ** testing if installed package can be loaded from final location ?????? C:/Users/gxd006/DOWNLO1/R-401.2 /etc/Renviron.site ?? May 12 19:25:09 Warning: replacing previous import ‘data.table::month’ by ‘lubridate::month’ when loading ‘IVIM’ 25.2 * Setup This is what you already have: - “Original”” folder, with no specific structure, with R and Rmd files that contain: a) functions that that you want to be re-used by others (and yourself many months later!). - They are tested and test codes are included in if(F) or in separate .Rmd, or, even better, in interactive Shiny App (eg https://rCanada.shinyapp.io/covid) - Good idea to be have them in form that can be sourced: source(\"caCovid.R\"); source(\"iviBase.R\") functions and other codes that are not (yet) ready for re-use. https://gccode.ssc-spc.gc.ca/r4gc/codes/tracking-covid-data - caCovid.R - iviBase.R - … common.R, plot.R, etc This is what you want to get: - Package folder (or several folders). - GCCode/r4gc/packages/rCanada - GCCode/r4gc/packages/IVI https://gccode.ssc-spc.gc.ca/gorodnichy/rCanada 25.2.0.1 Ways to do it: You can create it in two ways: 25.2.0.1.0.1 From New Project Either way RStudio will initialize and launch your new project. In the second way, it also puts .gitignore In RStudio -&gt; New Project -&gt; New Direcory -&gt;R package -&gt; package name: caPSES NB: there are many templates. Choose basic (“R package) and create in folder /my_packages NB: If you have .R codes that are already source-able, attached them with”Add”button (one at a time), or you can copy them into /R folder later note from Hadley: https://r-pkgs.org/workflows101.html Call usethis::create_package(“path/to/package/pkgname”). Or, In RStudio, do File &gt; New Project &gt; New Directory &gt; R Package. This ultimately calls usethis::create_package(), so really there’s just one way. Don’t use package.skeleton() to create a package. Because this function comes with R, you might be tempted to use it, but it creates a package that immediately throws errors with R CMD build. 25.2.0.1.0.2 From script Run from any R, Rmd window or R console the command below NB: output from &gt; devtools::create(&quot;../r4gc/packages/rCanada&quot;) &gt; #or usethis::create_package(&quot;../r4gc/packages/rCanada2&quot;) New project &#39;rCanada&#39; is nested inside an existing project &#39;../r4gc/packages/&#39;, which is rarely a good idea. If this is unexpected, the here package has a function, `here::dr_here()` that reveals why &#39;../r4gc/packages/&#39; is regarded as a project. Do you want to create anyway? 1: Yes 2: Absolutely not 3: Nope Selection: 1 √ Creating &#39;../r4gc/packages/rCanada/&#39; √ Setting active project to &#39;C:/Users/gxd006/Downloads/_CODES/GCCode/r4gc/packages/rCanada&#39; √ Creating &#39;R/&#39; √ Writing &#39;DESCRIPTION&#39; Package: rCanada Title: What the Package Does (One Line, Title Case) Version: 0.0.0.9000 Authors@R (parsed): * First Last &lt;first.last@example.com&gt; [aut, cre] (YOUR-ORCID-ID) Description: What the package does (one paragraph). License: `use_mit_license()`, `use_gpl3_license()` or friends to pick a license Encoding: UTF-8 LazyData: true Roxygen: list(markdown = TRUE) RoxygenNote: 7.1.1 √ Writing &#39;NAMESPACE&#39; √ Writing &#39;rCanada.Rproj&#39; √ Adding &#39;^rCanada\\\\.Rproj$&#39; to &#39;.Rbuildignore&#39; √ Adding &#39;.Rproj.user&#39; to &#39;.gitignore&#39; √ Adding &#39;^\\\\.Rproj\\\\.user$&#39; to &#39;.Rbuildignore&#39; √ Opening &#39;C:/Users/gxd006/Downloads/_CODES/GCCode/r4gc/packages/rCanada/&#39; in new RStudio session √ Setting active project to &#39;&lt;no active project&gt;&#39; 25.3 * Overall Workflow 25.3.0.1 .. Copy needed codes from MY_CODES to R directory Copy a function dt.replaceAwithB &lt;- function(dt, col, a, b) { dt[get(col)==a, (col):=b]; } Insert roxigen skeleton (from magic wand menu) and add description NB: you may need to manually insert @ import and @ export 25.3.1 no need to Load All? Always start from “Clean and rebuild” Then Check 25.4 * .Rbuildignore ^.*.Rproj$ ^.Rproj.user$ MY_CODES incorrect ^MY_CODES$ correct ^MY_DATASETS$ ^LICENSE.md$ 25.5 * License: use_mit_license() License: MIT + file LICENSE 25.6 * DESCRIPTION 25.7 * NAMESPACE https://r-pkgs.org/namespace.html use_package(&quot;data.table&quot;) ## &gt; use_package(&quot;data.table&quot;) ## √ Adding &#39;data.table&#39; to Imports field in DESCRIPTION ## * Refer to functions with `data.table::fun()` However this does notchange NAMESPACE ! Who changes is it? is that devtools::document() ??? Generated by roxygen2: do not edit by hand export() export(addDerivatives) export(extractMostInfectedToday) export(readCovidUofT.csv) importFrom(lubridate,dmy) importFrom(stringr,str_replace) I deleted NAMESPACE so that roxigen can generate it! then added manually there . Not sure that’s theway to do it ! import(data.table) import(ggplot2) import(lubridate) import(magrittr) import(IVIM) It Worked ! If you are using just a few functions from another package, the recommended option is to note the package name in the Imports: field of the DESCRIPTION file and call the function(s) explicitly using ::, e.g., pkg::fun(). Alternatively, though no longer recommended due to its poorer readability, use @importFrom, e.g., @importFrom pgk fun, and call the function(s) without ::. 25.8 * Examples and tests 25.8.0.1 .. In main file in /R folder #&#39; @examples Some could be such : #&#39; \\dontrun{} 25.8.0.2 .. In /tests folder &gt; use_testthat() √ Setting active project to &#39;C:/Users/gxd006/Downloads/_CODES/GCCode/r4gc/packages/IVIM&#39; √ Adding &#39;testthat&#39; to Suggests field in DESCRIPTION √ Setting Config/testthat/edition field in DESCRIPTION to &#39;3&#39; √ Creating &#39;tests/testthat/&#39; √ Writing &#39;tests/testthat.R&#39; * Call `use_test()` to initialize a basic test file and open it for editing. Warning messages: 1: In readLines(f, n) : incomplete final line found on &#39;C:/Users/gxd006/Downloads/_CODES/GCCode/r4gc/packages/IVIM/DESCRIPTION&#39; ... incomplete final line found on &#39;C:/Users/gxd006/Downloads/_CODES/GCCode/r4gc/packages/IVIM/DESCRIPTION&#39; &gt; use_vignette() Error in check_vignette_name(name) : argument &quot;name&quot; is missing, with no default 25.9 .. in MY_CODES Provide as .R, Rmd or shiny 25.10 * testthat https://testthat.r-lib.org/ 25.11 * Documentation devtools::document() https://kbroman.org/pkg_primer/pages/docs.html #&#39; For more details see the help vignette: #&#39; \\code{vignette(&quot;help&quot;, package = &quot;mypkg&quot;)} or \\href{../doc/help.html}{\\code{vignette(&quot;help&quot;, package = &quot;mypkg&quot;)}} 25.12 * Vignettes &gt; use_vignette(name=&quot;my_vignettes&quot;) √ Adding &#39;knitr&#39; to Suggests field in DESCRIPTION √ Setting VignetteBuilder field in DESCRIPTION to &#39;knitr&#39; √ Adding &#39;inst/doc&#39; to &#39;.gitignore&#39; √ Creating &#39;vignettes/&#39; √ Adding &#39;*.html&#39;, &#39;*.R&#39; to &#39;vignettes/.gitignore&#39; √ Adding &#39;rmarkdown&#39; to Suggests field in DESCRIPTION √ Writing &#39;vignettes/my_vignettes.Rmd&#39; * Modify &#39;vignettes/my_vignettes.Rmd&#39; I later renamed my first vignette to intro.Rmd - manually https://bookdown.org/yihui/rmarkdown-cookbook/package-vignette.html 25.13 Delivering package [Easiest way] Put binary in package repo. Then you can install it simply using install.packages(\"IVIM\", repos = \"https://gccode.ssc-spc.gc.ca/r4gc/gc-packages/IVIM/-/blob/master/versions/IVIM_0.0.0.9000.tar.gz\") this .tar ball is obtained by running devtools::build() or devtools::check() which will place it in “../yourRPackageProject” directory. [CONFIRM THIS!] Put source in github. Then people will be able to install using devtools::install_github(\"https://gccode.ssc-spc.gc.ca/r4gc/gc-packages/IVIM\") 25.14 Packaging and publishing w. pkgdown https://fanwangecon.github.io/R4Econ/support/development/fs_packaging.pdf 25.14.0.1 Appendix: Various possible Errors and problems 25.14.0.1.0.1 Errors in using usethis::use_testthat() Problem: &gt; usethis::use_vignette(name=&quot;howtoCovid&quot;) Error in read.dcf(con) : Line starting &#39;analyze and visualiz ...&#39; is malformed! &gt; Solution: https://stackoverflow.com/questions/59303030/devtools-error-in-read-dcfpath-desc-line-starting-this-corresponds-to Corrections from https://gccode.ssc-spc.gc.ca/r4gc/gc-packages/IVIM/-/tree/useR-dev/ 25.15 (optional) Rtools NBL This is not required https://cran.r-project.org/bin/windows/Rtools/ http://web.mit.edu/insong/www/pdf/rpackage_instructions.pdf 25.15.0.1 package_initialization_script.R ## package_initialization_script.R library(devtools) devtools::create(&quot;rCanada&quot;) ## if you are in /my_package devtools::create(&quot;../../rCanada&quot;) ## will it erase it,if I lready have it? &gt; #or usethis::create_package(&quot;../r4gc/packages/rCanada2&quot;) library(roxygen2) ## library(testthis). What&#39;s the difference from library(testthat) ?? library(testthat) ## do we need it? ## Attaching package: ‘testthat’ # ## The following object is masked from ‘package:devtools’: # ## test_file # ## The following objects are masked from ‘package:magrittr’: # ## equals, is_less_than, not usethis::use_testthat() ## from usethis, which is callsed from devtools use_vignette(name=&quot;my_vignettes&quot;) # use_vignette(name=&quot;data_linking&quot;) use_package(&quot;data.table&quot;) use_package(&quot;magrittr&quot;) use_package(&quot;data.table&quot;) use_package(&quot;lubridate&quot;, type=&quot;Imports&quot;) ## how about order ?! lubridate must be after data.table ! use_package(&quot;stringr&quot;) "],["r101-building-covid-19-tracker-app-from-scratch.html", "26 R101: Building COVID-19 Tracker App from scratch", " 26 R101: Building COVID-19 Tracker App from scratch The following page provides codes and video-recording for this tutorial: https://open-canada.github.io/UseR/learn2020.html You can see the final result here: https://itrack.shinyapps.io/covid/us.Rmd "],["gc-data.html", "27 GC Open Data use cases 27.1 PSES Results interactive analysis and visualization: 27.2 Automated ATIP requests topic extraction: 27.3 Automated municipal level COVID-19 tracker: 27.4 Geo-mapped current, historical and predicted border wait times:", " 27 GC Open Data use cases Additional codes are applications developed by the community are described in Shiny Apps and “Lunch and Learn” 27.1 PSES Results interactive analysis and visualization: URL: https://open-canada.github.io/Apps/pses Source: https://gccode.ssc-spc.gc.ca/r4gc/codes/pses No other Open Canada data is of as much common interest across the government as the PSES results [^11]. These data contain the information about all GC departments, their organizational structure and performance. A Shiny App prototype is developed to perform three most desired tasks one wished to do with these data (see Figure): [^11] https://www.canada.ca/en/treasury-board-secretariat/services/innovation/public-service-employee-survey.html Vertical result tracking: results comparison across an organization, automated detection and visualization of the performance variation across the organization - for any given PSES question. Horizontal results tracking: results comparison over time - for any given unit, in comparison to the organization and Public Service averages Performance summary by theme: automated generation of report cards that show the performance at each level of the organization for each of theme and in relation to the rest of the organization and Public Service average. Automated generation of full report with detailed comparative analysis and recommendations: for each unit and each level of organization Figure. Key functionalities of the PSES App prototype: a) vertical results tracking - for any question over entire organization, b) horizontal results tracking - for any unit over time, and c) performance report summary - for each unit, by theme, and in comparison to the Public Service average (shown as crosses) and other units within organization (shown as small dots). The results can be displayed filtered and sorted by score, ranking percentile, org. structure, number of responses, by theme or question. 27.1.1 Other tools and dashboards TBS Official PSES Results viewer (developed in PowerBI): https://hranalytics-analytiquerh.tbs-sct.gc.ca/Home/ReportList/2019?GoCTemplateCulture=en-CA Direct link to PowerBI here: https://hranalytics-analytiquerh.tbs-sct.gc.ca/Home/EmbedReport/6?GoCTemplateCulture=en-CA ​ 27.2 Automated ATIP requests topic extraction: Source: https://gccode.ssc-spc.gc.ca/r4gc/codes/atip Another Open Canada dataset that relates to the performance of many GC departments is the ATIP requests dataset [^22]. An interactive Natural Language Processing (NLP) application has been developed to enable the analysis and visualization of these requests for each participating department (see Figure 2). Its functionalities include: statistics summary, automated key-words and topic extraction using N-grams, document term matrix and Latent Dirichlet Allocation. The topics can be visualized as word-clouds or as graphs that connect the related words. [^22] https://open.canada.ca/en/search/ati. See “Text Mining with R!” by Julia Silge and David Robinson (https://www.tidytextmining.com) for definitions of the terms. Figure 2. Key functionalities of the ATIP App: a) department specific bi-variable statics (such as dispositions by year, shown in the image), b) department specific key topics, visualized as correlated terms graphs , c) key topics for each participating department, visualized as N-gram frequency bars (such as 2-gram, or two-word combination, shown in the image). 27.3 Automated municipal level COVID-19 tracker: URL: https://open-canada.github.io/Apps/covid (See also: https://itrack.shinyapps.io/covid/us.Rmd). Source: https://gccode.ssc-spc.gc.ca/r4gc/codes/covid This App was built at the beginning of the pandemic. It uses open COVID-19 data for Canada and US to allow one to summarize, search and sort the results by geographical proximity using a variety of criteria (see Figure 3). More details about it and a tutorial on how to build it are provided at https://open-canada.github.io/UseR/learn2020 27.4 Geo-mapped current, historical and predicted border wait times: URL: https://open-canada.github.io/Apps/border (redirect to open.canada.ca). Source: https://gccode.ssc-spc.gc.ca/gorodnichy/simborder This App (shown in Figure 4) combines Open geo-spatial data with Open historical and current border wait times data to predict and visualize delays at Canadian land border crossings. The App is included (entitled iTrack-Border) in the Open Canada Apps Gallery at https://open.canada.ca/en/apps, where more information about it can be found. "],["shiny-apps.html", "28 Shiny Apps 28.1 PSES Results interactive analysis and visualization: 28.2 Automated ATIP requests topic extraction: 28.3 Automated municipal level COVID-19 tracker: 28.4 Geo-mapped current, historical and predicted border wait times: 28.5 Demo and tool for linking noisy data records: 28.6 Html pages comparator: 28.7 Large table summarizer:", " 28 Shiny Apps Source: https://open-canada.github.io/Apps/ These Applications have been built with contributions from data scientists across the Government of Canada, using open source tools and data, many as an outcome of the R4GC community training and socializing. Additional codes are applications developed by the community are described in GC Data use-cases and “Lunch and Learn” 28.1 PSES Results interactive analysis and visualization: URL: https://open-canada.github.io/Apps/pses Source: https://gccode.ssc-spc.gc.ca/r4gc/codes/pses No other Open Canada data is of as much common interest across the government as the PSES results [^11]. These data contain the information about all GC departments, their organizational structure and performance. A Shiny App prototype is developed to perform three most desired tasks one wished to do with these data (see Figure): [^11] https://www.canada.ca/en/treasury-board-secretariat/services/innovation/public-service-employee-survey.html Vertical result tracking: results comparison across an organization, automated detection and visualization of the performance variation across the organization - for any given PSES question. Horizontal results tracking: results comparison over time - for any given unit, in comparison to the organization and Public Service averages Performance summary by theme: automated generation of report cards that show the performance at each level of the organization for each of theme and in relation to the rest of the organization and Public Service average. Automated generation of full report with detailed comparative analysis and recommendations: for each unit and each level of organization Figure. Key functionalities of the PSES App prototype: a) vertical results tracking - for any question over entire organization, b) horizontal results tracking - for any unit over time, and c) performance report summary - for each unit, by theme, and in comparison to the Public Service average (shown as crosses) and other units within organization (shown as small dots). The results can be displayed filtered and sorted by score, ranking percentile, org. structure, number of responses, by theme or question. 28.1.1 Other tools and dashboards TBS Official PSES Results viewer (developed in PowerBI): https://hranalytics-analytiquerh.tbs-sct.gc.ca/Home/ReportList/2019?GoCTemplateCulture=en-CA Direct link to PowerBI here: https://hranalytics-analytiquerh.tbs-sct.gc.ca/Home/EmbedReport/6?GoCTemplateCulture=en-CA ​ 28.2 Automated ATIP requests topic extraction: Source: https://gccode.ssc-spc.gc.ca/r4gc/codes/atip Another Open Canada dataset that relates to the performance of many GC departments is the ATIP requests dataset [^22]. An interactive Natural Language Processing (NLP) application has been developed to enable the analysis and visualization of these requests for each participating department (see Figure 2). Its functionalities include: statistics summary, automated key-words and topic extraction using N-grams, document term matrix and Latent Dirichlet Allocation. The topics can be visualized as word-clouds or as graphs that connect the related words. [^22] https://open.canada.ca/en/search/ati. See “Text Mining with R!” by Julia Silge and David Robinson (https://www.tidytextmining.com) for definitions of the terms. Figure 2. Key functionalities of the ATIP App: a) department specific bi-variable statics (such as dispositions by year, shown in the image), b) department specific key topics, visualized as correlated terms graphs , c) key topics for each participating department, visualized as N-gram frequency bars (such as 2-gram, or two-word combination, shown in the image). 28.3 Automated municipal level COVID-19 tracker: URL: https://open-canada.github.io/Apps/covid (See also: https://itrack.shinyapps.io/covid/us.Rmd). Source: https://gccode.ssc-spc.gc.ca/r4gc/codes/covid This App was built at the beginning of the pandemic. It uses open COVID-19 data for Canada and US to allow one to summarize, search and sort the results by geographical proximity using a variety of criteria (see Figure 3). More details about it and a tutorial on how to build it are provided at https://open-canada.github.io/UseR/learn2020 28.4 Geo-mapped current, historical and predicted border wait times: URL: https://open-canada.github.io/Apps/border (redirect to open.canada.ca). Source: https://gccode.ssc-spc.gc.ca/gorodnichy/simborder This App (shown in Figure 4) combines Open geo-spatial data with Open historical and current border wait times data to predict and visualize delays at Canadian land border crossings. The App is included (entitled iTrack-Border) in the Open Canada Apps Gallery at https://open.canada.ca/en/apps, where more information about it can be found. 28.5 Demo and tool for linking noisy data records: URL: https://rcanada.shinyapps.io/demo/ (presented at the #GC Data2021 Conference ) This App was demonstrated and used for training in the “Data Engineering Challenges and Solutions: Demo of Shiny” workshop at 2021 GC Data Conference, Data Literacy Fest . Its key functionalities include: Single variable cleaning tasks (demo mode): automated extraction of date and timestamps from arbitrarily typed strings (as shown in Figure 5.a); rectification and correction of Canadian postal codes; fuzzy matching of names. Multi-variable linking tasks (demo mode): city names deduplication; deduplication and linking of name records. Use cases (live Web crawling mode): automated extraction of name variants and important dates from Web. “Test it!” mode: fuzzy linking and deduplication of user-uploaded multi-variable data records, using a variety of string similarity metrics and thresholds (as shown in Figure 5.b). 28.6 Html pages comparator: Source: https://gccode.ssc-spc.gc.ca/r4gc/resources/text/similarity 28.7 Large table summarizer: Source: https://gccode.ssc-spc.gc.ca/r4gc/codes/shiny/-/tree/master/table-summarizer "],["lunch-and-learn-notes.html", "A Lunch and Learn notes A.1 Geo/Spatial coding and visualization with R. Part 1: A.2 Text Analysis with R. Part 1: A.3 Dual Coding - Python and R unite ! A.4 Working with ggtables A.5 Automate common look and feel of your ggplot graphs A.6 Automated generation of report cards A.7 Discussed RStudio Webinars", " A Lunch and Learn notes These are the draft notes from the Lunch and Learn ‘Data Science with R’ series organized by R4GC community. Please see Lunch and Learn page for details on how to join these meetings. For video-recordings and additional notes, please join Lunch and Learn ‘Data Science with R’ GCcollab group Interactive Outputs in R without Shiny 26 Nov 2021 - This meeting will be dedicated to tools to generate interactive graphs, tables, and other content without Shiny (which, as you know, requires a server to host your Shiny application and which for this reason cannot be easily shared with your clients, e.g. by email) Here are the most popular ones: https://rstudio.github.io/DT/ https://plotly.com/r/ and https://glin.github.io/reactable. Many worked with plotly and DT, but reactable is another great package, which will make your outputs loved by your clients. 12 Nov - 19 Nov 2021: Text Analysis with R follow-up / Converting codes to Shiny App 8 Oct 2021: Text Analysis with R. Part 1: identifying near-duplicate documents 1 Oct 2021: Shiny App to summarize very large, high-dimensional tables (code &amp; app provided) 30 Jul - 17 Sep 2021: Geo/Spatial coding and visualization with R. (code provided) 16 Jul 2021: Dual Coding - Python and R unite ! (code provided) 9 Jul 2021: Exploring ggplots (recording, code provided) 2 Jul 2021: Parsing GC Tables (code provided) 25 Jun 2021: Using the Open Government Portal API within R (recording, code on github.com/open-canada) 21 Apr 2021: Analyzing PSES results using R and Shiny 16 Apr - 15 May 2021: Building R packages (recording, codes provided) A.1 Geo/Spatial coding and visualization with R. Part 1: Contributed by: A.2 Text Analysis with R. Part 1: Contributed by: A.3 Dual Coding - Python and R unite ! Contributed by: A.4 Working with ggtables Contributed by: A.5 Automate common look and feel of your ggplot graphs Contributed by: A.6 Automated generation of report cards Contributed by: A.7 Discussed RStudio Webinars Webinars at RStudio - https://www.rstudio.com/resources/webinars/ (codes at https://github.com/rstudio/webinars) The new insights from these webinars and other R-related blogs and events are discussed at R4GC community meetups "],["canada-related-open-source-r-codes-and-packages.html", "B Canada-related Open source R codes and packages B.1 Packages on CRAN B.2 Packages not on CRAN B.3 Codes on GitHub", " B Canada-related Open source R codes and packages B.1 Packages on CRAN One can go to https://packagemanager.rstudio.com/ to search and explore packages. Install them from Tools-&gt; Install Packages in RStudio, or directly using the line below: install.packages(&#39;cansim&#39;) ` B.1.0.1 CANSIM2R - Directly Extracts Complete CANSIM Data Tables Extract CANSIM (Statistics Canada) tables and transform them into readily usable data in panel (wide) format. It can also extract more than one table at a time and produce the resulting merge by time period and geographical region. B.1.0.2 cansim - Accessing Statistics Canada Data Table and Vectors https://github.com/mountainMath/cansim Searches for, accesses, and retrieves new-format and old-format Statistics Canada data tables, as well as individual vectors, as tidy data frames. This package deals with encoding issues, allows for bilingual English or French language data retrieval, and bundles convenience functions to make it easier to work with retrieved table data. Optional caching features are provided. B.1.0.3 cancensus https://github.com/mountainMath/cancensus See also censusmapper B.1.0.4 https://github.com/mountainMath/tongfen B.1.0.5 https://github.com/mountainMath/statcanXtabs B.1.0.6 https://github.com/warint/statcanR statcanR Easily connect to Statistics Canada’s Web Data Service with R. Open economic data (formerly known as CANSIM tables, now identified by Product IDs (PID)) are accessible as a data frame, directly in the user’s R environment. B.1.0.7 install.packages(‘canadamaps’) Terrestrial maps with simplified topologies for Census Divisions, Agricultural Regions, Economic Regions, Federal Electoral Divisions and Provinces. B.2 Packages not on CRAN B.2.0.1 https://github.com/VLucet/rgovcan rgovcan Easy access to the Canadian Open Government Portal B.2.0.2 https://github.com/bcgov/canwqdata canwqdata An R package to download open water quality data from Environment and Climate Change Canada’s National Long-term Water Quality Monitoring Data. B.3 Codes on GitHub B.3.1 Expenditures and procurement B.3.1.1 https://github.com/nmarum/canadadefencespending Data wrangling and exploratory analysis of publicly available data about National Defence expenditures and defence procurement. B.3.2 Health and Environment B.3.2.1 https://github.com/dbuijs/HealthCanadaOpenData A project for importing open data from Health Canada’s website into R. B.3.3 Elections B.3.3.1 2019 Canadian election forecast B.3.3.2 https://github.com/thisismactan/Canada-2019 This is the repository for the Election StatSheet 2019 Canadian election forecast. B.3.3.3 2015 Canadian Election Data https://github.com/lchski/canada-2015-federal-election-data B.3.3.4 https://github.com/lchski/canada-2015-federal-election-data 2015 Canadian Election Data B.3.3.5 FPTP Election Strategizer “FPTP Election Strategizer: A data-science driven tool to mitigate the political biases of the First Past The Post electoral system in Canada” - Research article, with R code and visualizations in support of Fair Vote Canada https://github.com/ivi-m/election-strategizer/ B.3.4 Ottawa B.3.4.1 https://github.com/whipson/Ottawa_Bicycles Data and cleaning scripts for Ottawa Bicycle Counter shiny app. B.3.4.2 https://github.com/lchski/ottawa-fire-stations Mapping Ottawa’s fire stations B.3.5 Vancouver Many codes, packages, and blogs related to Vancouver and Canada, and other utility functions, are developed by MountainMath (Jens von Bergman) - Source: https://github.com/mountainMath B.3.6 Other related packages From jennybc googlesheets Public Google Spreadsheets R API googleComputeEngineR Public Forked from cloudyr/googleComputeEngineR "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
